{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from daily_dialog import DailyDialog\n",
    "\n",
    "builder = DailyDialog()\n",
    "builder.download_and_prepare()\n",
    "dataset = builder.as_dataset()\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "from datasets import DatasetDict\n",
    "\n",
    "# Load a pre-trained tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize the dialogues (flattening lists of utterances)\n",
    "def tokenize_function(example):\n",
    "    # Check if each dialog entry is a list of strings and join them\n",
    "    if isinstance(example['dialog'], list):\n",
    "        example['dialog'] = [' '.join(dialog) if isinstance(dialog, list) else dialog for dialog in example['dialog']]\n",
    "    \n",
    "    return tokenizer(example['dialog'], padding='max_length', truncation=True, max_length=128)\n",
    "\n",
    "# Apply the tokenizer to the entire dataset\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "\n",
    "# Format the dataset for PyTorch or TensorFlow\n",
    "tokenized_datasets.set_format(type='torch', columns=['input_ids', 'attention_mask'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset_structure(dataset):\n",
    "    for split_name, split_data in dataset.items():\n",
    "        print(f\"\\n--- {split_name.upper()} SPLIT ---\")\n",
    "        print(f\"Number of rows: {len(split_data)}\")\n",
    "        print(\"Columns:\", split_data.column_names)\n",
    "        \n",
    "        # Print a sample of the data (e.g., the first entry)\n",
    "        print(\"\\nSample data (first entry):\")\n",
    "        sample = split_data[0]\n",
    "        for key, value in sample.items():\n",
    "            # If the value is a long list (e.g., input_ids), print only the start for brevity\n",
    "            if isinstance(value, list) and len(value) > 10:\n",
    "                print(f\"{key}: {value[:10]}... (truncated)\")\n",
    "            else:\n",
    "                print(f\"{key}: {value}\")\n",
    "\n",
    "# Print the structure of the tokenized_datasets\n",
    "print_dataset_structure(tokenized_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train\n",
    "\n",
    "train.run(total_epoch=50, best_loss=float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized DialogLoader with bert-base-uncased tokenizer\n",
      "Loading DailyDialog dataset...\n",
      "Dataset loaded successfully\n",
      "Tokenizing dataset...\n",
      "Formatting dataset for PyTorch...\n",
      "Dataset preparation complete\n",
      "Training step: 0/348 (0.0%), Loss: 75423.3359\n",
      "Training step: 34/348 (9.8%), Loss: 107.2147\n",
      "Training step: 68/348 (19.5%), Loss: 17.0420\n",
      "Training step: 102/348 (29.3%), Loss: 7.9631\n",
      "Training step: 136/348 (39.1%), Loss: 3.8269\n",
      "Training step: 170/348 (48.9%), Loss: 3.6748\n",
      "Training step: 204/348 (58.6%), Loss: 3.1389\n",
      "Training step: 238/348 (68.4%), Loss: 3.2853\n",
      "Training step: 272/348 (78.2%), Loss: 3.0937\n",
      "Training step: 306/348 (87.9%), Loss: 2.9659\n",
      "Training step: 340/348 (97.7%), Loss: 3.2965\n",
      "Training step: 347/348 (99.7%), Loss: 4.0055\n",
      "Epoch: 1 | Time: 0m 49s\n",
      "\tTrain Loss: 1474.612\n",
      "\tValid Loss: 1.882\n",
      "\tAct Accuracy: 0.549\n",
      "\tEmotion Accuracy: 0.702\n",
      "\n",
      "==================================================\n",
      "Training completed! Best checkpoint saved at:\n",
      "saved/model-1.882.pt\n",
      "Best validation loss: 1.882\n",
      "==================================================\n",
      "\n",
      "Collecting SAE metadata...\n",
      "Debug - encoded shape: torch.Size([])\n",
      "Debug - encoded shape: torch.Size([])\n",
      "Debug - encoded shape: torch.Size([])\n",
      "Debug - encoded shape: torch.Size([])\n",
      "Debug - encoded shape: torch.Size([])\n",
      "Debug - encoded shape: torch.Size([])\n",
      "Debug - encoded shape: torch.Size([])\n",
      "Debug - encoded shape: torch.Size([])\n",
      "Debug - encoded shape: torch.Size([])\n",
      "Debug - encoded shape: torch.Size([])\n",
      "Error concatenating activations: zero-dimensional arrays cannot be concatenated\n",
      "First activation shape: ()\n",
      "Metadata keys: dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import train \n",
    "%matplotlib inline\n",
    "import analysis.sae_analyzer as SAEAnalyzer\n",
    "\n",
    "# Run the training\n",
    "# When training:\n",
    "model, valid_iter, device, sae_metadata = train.main(total_epoch=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if 'analysis.sae_analyzer' in sys.modules:\n",
    "    del sys.modules['analysis.sae_analyzer']\n",
    "\n",
    "# Then reload the module\n",
    "from analysis.sae_analyzer import SAEAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'activations'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m analyzer \u001b[38;5;241m=\u001b[39m SAEAnalyzer\u001b[38;5;241m.\u001b[39mfrom_metadata(sae_metadata)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Now you can interactively analyze the results\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# For example:\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43manalyzer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_activation_distribution\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m     10\u001b[0m analyzer\u001b[38;5;241m.\u001b[39mplot_feature_correlations()\n",
      "File \u001b[0;32m~/code/transformer_implementation/analysis/sae_analyzer.py:23\u001b[0m, in \u001b[0;36mSAEAnalyzer.plot_activation_distribution\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     21\u001b[0m     activations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_activations()\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 23\u001b[0m     activations \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mactivations\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     25\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m     26\u001b[0m sns\u001b[38;5;241m.\u001b[39mhistplot(activations\u001b[38;5;241m.\u001b[39mflatten(), bins\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'activations'"
     ]
    }
   ],
   "source": [
    "# Create analyzer from metadata (no need to recompute)\n",
    "analyzer = SAEAnalyzer.from_metadata(sae_metadata)\n",
    "\n",
    "\n",
    "# Now you can interactively analyze the results\n",
    "# For example:\n",
    "analyzer.plot_activation_distribution()\n",
    "plt.show()\n",
    "\n",
    "analyzer.plot_feature_correlations()\n",
    "plt.show()\n",
    "\n",
    "analyzer.plot_reconstruction_error()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.plot_feature_correlations()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.plot_feature_correlations()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.plot_reconstruction_error()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
